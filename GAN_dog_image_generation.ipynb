{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport math\nimport random\nimport time\nimport datetime\nfrom collections import defaultdict\nfrom tqdm import tqdm, tqdm_notebook\nimport xml.etree.ElementTree as ET \nimport cv2\nimport PIL\nfrom keras import backend as K\nimport gc\nimport scipy.misc\nfrom utils import *\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport sys\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"HEIGHT, WIDTH, CHANNEL = 64, 64, 3\nBATCH_SIZE = 512\nEPOCH = 5000\nBUFFER_SIZE = 1024\nimage_width = HEIGHT\nimage_height = WIDTH\nimage_channels = CHANNEL\nimage_sample_size = 10000\nimage_output_dir = '../output_images/'\nimage_input_dir = '../input/all-dogs/all-dogs/'\nimage_ann_dir = \"../input/annotation/Annotation/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog_breed_dict = {}\nfor annotation in os.listdir(image_ann_dir):\n    annotations = annotation.split('-')\n    dog_breed_dict[annotations[0]] = annotations[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_input_image_dict(image_input_dir, labels_dict):\n    image_sample_dict = defaultdict(list)\n    for image in os.listdir(image_input_dir):\n        filename = image.split('.')\n        label_code = filename[0].split('_')[0]\n        breed_name = labels_dict[label_code]\n        #print('Code: {}, Breed: {}'.format(label_code, breed_name))\n        if image is not None:\n            image_sample_dict[breed_name].append(image)\n    \n    print('Created label dictionary for input images.')\n    return image_sample_dict\nimage_sample_dict = get_input_image_dict(image_input_dir, dog_breed_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(image_sample_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_class_distributions(image_sample_dict, title=''):\n    class_lengths = []\n    labels = []\n    total_images = 0\n    \n    print('Total amount of dog breeds: ', len(image_sample_dict))\n    \n    for label, _ in image_sample_dict.items():\n        total_images += len(image_sample_dict[label])\n        class_lengths.append(len(image_sample_dict[label]))\n        labels.append(label)\n        \n    print('Total amount of input images: ', total_images)\n        \n    plt.figure(figsize = (10,30))\n    plt.barh(range(len(class_lengths)), class_lengths)\n    plt.yticks(range(len(labels)), labels)\n    plt.title(title)\n    plt.ylabel('Dog Breed')\n    plt.xlabel('Sample size')\n    plt.show()\n    \n    return total_images\n\n\n#total_images = plot_class_distributions(image_sample_dict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(src):\n    img = cv2.imread(src)\n    if img is None:\n        raise FileNotFoundError\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(directory, image_sample_dict, examples=9, disp_labels=True): \n  \n    if not math.sqrt(examples).is_integer():\n        print('Please select a valid number of examples.')\n        return\n    \n    imgs = []\n    classes = []\n    for i in range(examples):\n        rnd_class, _ = random.choice(list(image_sample_dict.items()))\n        #print(rnd_class)\n        rnd_idx = np.random.randint(0, len(image_sample_dict[rnd_class]))\n        filename = image_sample_dict[rnd_class][rnd_idx]\n        img = read_image(os.path.join(directory, filename))\n        imgs.append(img)\n        classes.append(rnd_class)\n    \n    \n    fig, axes = plt.subplots(round(math.sqrt(examples)), round(math.sqrt(examples)),figsize=(15,15),\n    subplot_kw = {'xticks':[], 'yticks':[]},\n    gridspec_kw = dict(hspace=0.3, wspace=0.1))\n    \n    for i, ax in enumerate(axes.flat):\n        if disp_labels == True:\n            ax.title.set_text(classes[i])\n        ax.imshow(imgs[i])\n#plot_images(image_input_dir, image_sample_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_cropped_images(dog_breed_dict=dog_breed_dict, image_ann_dir=image_ann_dir, sample_size=22125, \n                        image_width=image_width, image_height=image_height, image_channels=image_channels):\n    curIdx = 0\n    breeds = []\n    dog_images_np = np.zeros((sample_size,image_width,image_height,image_channels))\n    for breed_folder in os.listdir(image_ann_dir):\n        for dog_ann in tqdm(os.listdir(image_ann_dir + breed_folder)):\n            try:\n                img = read_image(os.path.join(image_input_dir, dog_ann + '.jpg'))\n            except FileNotFoundError:\n                print(\"nf\")\n                continue\n                \n            tree = ET.parse(os.path.join(image_ann_dir + breed_folder, dog_ann))\n            root = tree.getroot()\n            \n            size = root.find('size')\n            width = int(size.find('width').text)\n            height = int(size.find('height').text)\n            objects = root.findall('object')\n            for o in objects:\n                bndbox = o.find('bndbox') \n                \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n                \n                xmin = max(0, xmin - 4)        # 4 : margin\n                xmax = min(width, xmax + 4)\n                ymin = max(0, ymin - 4)\n                ymax = min(height, ymax + 4)\n\n                w = np.min((xmax - xmin, ymax - ymin))\n                w = min(w, width, height)                     # available w\n\n                if w > xmax - xmin:\n                    xmin = min(max(0, xmin - int((w - (xmax - xmin))/2)), width - w)\n                    xmax = xmin + w\n                if w > ymax - ymin:\n                    ymin = min(max(0, ymin - int((w - (ymax - ymin))/2)), height - w)\n                    ymax = ymin + w\n                \n                img_cropped = img[ymin:ymin+w, xmin:xmin+w, :]      # [h,w,c]\n                # Interpolation method\n                if xmax - xmin > image_width:\n                    interpolation = cv2.INTER_AREA          # shrink\n                else:\n                    interpolation = cv2.INTER_CUBIC         # expansion\n                    \n                img_cropped = cv2.resize(img_cropped, (image_width, image_height), \n                                         interpolation=interpolation)  # resize\n                    \n                dog_images_np[curIdx,:,:,:] = np.asarray(img_cropped)\n                dog_breed_name = dog_breed_dict[dog_ann.split('_')[0]]\n                breeds.append(dog_breed_name)\n                curIdx += 1\n    \n    return dog_images_np, breeds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\ndog_images_np, breeds = load_cropped_images()\ndog_images_np = (dog_images_np)/255\nest_time = round(time.time() - start_time)\nprint(\"Feature loading time: {}.\".format(str(datetime.timedelta(seconds=est_time))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lrelu(x, n, leak=0.2): \n    return tf.maximum(x, leak * x, name=n) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_features(features, labels, image_width=image_width, image_height=image_height, \n                image_channels=image_channels,\n                examples=25, disp_labels=True): \n  \n    if not math.sqrt(examples).is_integer():\n        print('Please select a valid number of examples.')\n        return\n    \n    imgs = []\n    classes = []\n    for i in range(examples):\n        rnd_idx = np.random.randint(0, len(labels))\n        imgs.append((features[rnd_idx, :, :, :]))\n        classes.append(labels[rnd_idx])\n    \n    \n    fig, axes = plt.subplots(round(math.sqrt(examples)), round(math.sqrt(examples)),figsize=(15,15),\n    subplot_kw = {'xticks':[], 'yticks':[]},\n    gridspec_kw = dict(hspace=0.3, wspace=0.01))\n    \n    for i, ax in enumerate(axes.flat):\n        if disp_labels == True:\n            ax.title.set_text(classes[i])\n        ax.imshow(imgs[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loaded features shape: ', dog_images_np.shape)\nprint('Loaded labels: ', len(breeds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"print('Plotting cropped images by specified coordinates..')\n#plot_features(dog_images_np, breeds, examples=4, disp_labels=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****PlaceHolder****"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dog_images_np_tens = tf.placeholder(dtype=tf.float32, shape=[dog_images_np.shape[0],64,64,3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = tf.get_variable('w', [dog_images_np.shape[0],64,64,3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w.assign(dog_images_np)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# images_batch = tf.train.shuffle_batch(\n#                                     [dog_images_np], batch_size = BATCH_SIZE,\n#                                     num_threads = 4, capacity = 2000 + 3* BATCH_SIZE,\n#                                     min_after_dequeue = 200).batch(BATCH_SIZE)\n# dog_images_np_tens = tf.data.Dataset.from_tensor_slices(dog_images_np).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ndog_images_np_tens = tf.random.shuffle(w,seed = 40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog_images_np_tens = tf.split(dog_images_np_tens,75)#375,59","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog_images_np_tens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del w\n# del dog_images_np\nimport pprint\n#pprint.pprint(locals())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dict(zip(locals(),[sys.getsizeof(i)*len(i) for i in locals()])), sep='\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndel get_input_image_dict, image_sample_dict, dog_breed_dict, annotations, breeds, dog_images_np, w, plot_class_distributions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator( reuse=True):\n    input_img = tf.keras.Input(shape = (64,64,3))\n    \n    x = layers.Conv2DTranspose(256, (3, 3), padding='same', name = \"genConvTr1\")(input_img)\n    x = layers.BatchNormalization(name = \"genBn1\")(x)\n    x = layers.LeakyReLU(alpha = 0.2, name = \"genLr1\")(x)\n    x = layers.Conv2DTranspose(128, (3, 3), padding='same', name = \"genConvTr2\")(x)\n    x = layers.BatchNormalization(name = \"genBn2\")(x)\n    x = layers.LeakyReLU(alpha = 0.2, name = \"genLr2\")(x)\n#     x = layers.Conv2DTranspose(64, (3, 3), padding='same', name = \"genConvTr3\")(x)\n#     x = layers.BatchNormalization(name = \"genBn3\")(x)\n#     x = layers.LeakyReLU(alpha = 0.2, name = \"genLr3\")(x)\n    gen = layers.Conv2DTranspose(3, (3, 3), activation = 'tanh', padding='same', name = \"genConvTr_op\")(x)\n    \n    model = tf.keras.Model(input_img, gen)\n#     opt = tf.keras.optimizers.RMSprop(lr = 1e-5)#SGD(lr=0.05, momentum=0.5, nesterov=True)\n#     #loss_fn = cross_entropy(tf.ones_like(fake_output), fake_output)\n#     model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['mae'])\n    print(model.summary())\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator(reuse=True):#input, is_train, reuse=tf.AUTO_REUSE):\n    input_img = tf.keras.Input(shape = (64,64,3))\n    x = layers.Conv2D(64, (3, 3), padding='same', name = \"disConv1\")(input_img)\n    x = layers.LeakyReLU(alpha = 0.2, name = \"disLr1\")(x)\n    x = layers.Dropout(0.2, name = \"disDr1\")(x)\n    x = layers.Conv2D(128, (3, 3), padding='same', name = \"disConv2\")(x)\n    x = layers.LeakyReLU(alpha = 0.2, name = \"disLr2\")(x)\n    x = layers.Dropout(0.2, name = \"disDr2\")(x)\n    x = layers.Conv2D(128, (3, 3), padding='same', name = \"disConv3\")(x)\n    x = layers.LeakyReLU(alpha = 0.2, name = \"disLr3\")(x)\n    x = layers.Dropout(0.2, name = \"disDr3\")(x)\n    x = layers.Flatten(name = \"disFl1\")(x)\n    dis = layers.Dense(1, name = \"disDense1\", activation = 'relu')(x)\n    \n    model = tf.keras.Model(input_img, dis)\n#     opt = tf.keras.optimizers.Adam(lr = 1e-4)#SGD(lr=0.05, momentum=0.5, nesterov=True)\n#     cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    \n#     real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n#     fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n#     total_loss = real_loss + fake_loss\n#     model.compile(optimizer=opt, loss=total_loss, metrics=['mae'])\n    print(model.summary())\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_v = generator()\n\n#noise = tf.random.normal([1,64, 64, 3], dtype=tf.dtypes.float32, seed = 40)\n#generated_image = generator_v(noise)\n#tf.image.convert_image_dtype(generated_image, dtype=tf.dtypes.float32)\n\ndiscriminator_v = discriminator()\n#decision = discriminator_v(generated_image, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_dim = [64,64,3]\n\nreal_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\nrandom_input = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, CHANNEL], name='rand_input')\nis_train = tf.placeholder(tf.bool, name='is_train')\n\nfake_image = generator_v(random_input, is_train)\n\nreal_result = discriminator_v(real_image, is_train)\nfake_result = discriminator_v(fake_image, is_train)\n\nd_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  # This optimizes the discriminator.\ng_loss = -tf.reduce_mean(fake_result)  # This optimizes the generator.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nt_vars = tf.trainable_variables()\nd_vars = [var for var in t_vars if 'dis' in var.name]\ng_vars = [var for var in t_vars if 'gen' in var.name]\ntrainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list = d_vars)\ntrainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list = g_vars)\n# clip discriminator weights\n#d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nprint(sys.getsizeof(d_vars))\n# del t_vars","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.core.protobuf import config_pb2\nEPOCH = 50\nbatch_size = 295\nimage_batch, samples_num = dog_images_np_tens, 22125\n\nbatch_num = int(samples_num / batch_size)\nprint(batch_num)\ntotal_batch = 0\nsess = tf.Session()\nsaver = tf.train.Saver()\nsess.run(tf.global_variables_initializer(), options=config_pb2.RunOptions(\n        report_tensor_allocations_upon_oom=True))\nsess.run(tf.local_variables_initializer(), options=config_pb2.RunOptions(\n        report_tensor_allocations_upon_oom=True))\n# continue training\nversion = 0\nsave_path = saver.save(sess, \"/tmp/model.ckpt\")\nckpt = tf.train.latest_checkpoint('./model/' + str(version))\nsaver.restore(sess, save_path)\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\nprint('total training sample num:%d' % samples_num)\nprint('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\nprint('start training...')\nfor i in range(EPOCH):\n    print(\"Running epoch {}/{}...\".format(i, EPOCH))\n    for j in tqdm(range(batch_num)):\n        gc.collect()\n        #print(j)\n        d_iters = 5\n        g_iters = 1\n\n        train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64, 64, 3]).astype(np.float32)\n        for k in range(d_iters):\n#             print(k)\n            train_image = sess.run(image_batch[j])\n            #wgan clip weights\n#            sess.run(d_clip)\n\n            # Update the discriminator\n            _, dLoss = sess.run([trainer_d, d_loss],\n                                feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n        #xkcd = gc.collect()\n        # Update the generator\n        for k in range(g_iters):\n            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64, 64, 3]).astype(np.float32)\n            _, gLoss = sess.run([trainer_g, g_loss],\n                                feed_dict={random_input: train_noise, is_train: True})\n        #xkcd = gc.collect()\n\n        # print 'train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss)\n\n    # save check point every 500 epoch\n    if i == 50:\n       if not os.path.exists('./model/' + version):\n           os.makedirs('./model/' + version)\n       saver.save(sess, './model/' +version + '/' + str(i))  \n    #if i%50 == 0:\n        # save images\n     #   if not os.path.exists(newPoke_path):\n     #       os.makedirs(newPoke_path)\n     #   sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n     #   imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n        # imgtest = imgtest * 255.0\n        # imgtest.astype(np.uint8)\n     #   save_images(imgtest, [8,8] ,newPoke_path + '/epoch' + str(i) + '.jpg')\n\n    print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\ncoord.request_stop()\ncoord.join(threads)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test():\n    random_dim = 100\n    with tf.variable_scope('input'):\n        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n        random_input = tf.placeholder(tf.float32, shape=[None, 64, 64, 3], name='rand_input')\n        is_train = tf.placeholder(tf.bool, name='is_train')\n    \n    # wgan\n    fake_image = generator(random_input, random_dim, is_train)\n    real_result = discriminator(real_image, is_train)\n    fake_result = discriminator(fake_image, is_train, reuse=True)\n    sess = tf.InteractiveSession()\n    sess.run(tf.global_variables_initializer(), options=config_pb2.RunOptions(\n        report_tensor_allocations_upon_oom=True)\n    variables_to_restore = slim.get_variables_to_restore(include=['gen'])\n    print(variables_to_restore)\n    saver = tf.train.Saver(variables_to_restore)\n    ckpt = tf.train.latest_checkpoint('./model/' + version)\n    saver.restore(sess, ckpt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile \nfrom PIL import Image ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getDog(seed, index):\n        \n#         xx = np.zeros((64,64,3))\n#         xx[index] = 0.70\n#         xx[np.random.uniform(-1.0, 1.0, size=[batch_size, 64, 64, 3]).astype(np.float32)] = 0.30\n#         train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 64, 64, 3]).astype(np.float32)\n        img = generator_v.predict(seed, verbose = 1)\n        img = img*255\n        index = (index+1)%10000\n        return Image.fromarray( img.astype('uint8') ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = zipfile.PyZipFile('imagesx.zip', mode='w')\nd = DogGenerator()\nfor k in range(10):\n    img = d.getDog(np.random.uniform(-1.0, 1.0, size=[batch_size, 64, 64, 3]).astype(np.float32), k)\n    f = str(k)+'.png'\n    img.save(f,'PNG'); z.write(f); os.remove(f)\n    #if k % 1000==0: print(k)\nz.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip imagesx.zip -d /opt\nfor _ in list(os.listdir('/opt')[2:5]):\n    img = plt.imread('/opt/'+_)\n    plt.imshow(img)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}